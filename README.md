# Seq2Seq_En-Hr
Performance of OpenNMT sequence-to-sequence LM in translating English-Croatian

From a 2022 term paper in collaboration with Cameron Duval on "NMT Training and Morphological Learning of Low-Resource Languages":

Neural machine translation has been proven an effective tool for language translation. While NMT models are powerful and only use a fraction of the memory required for statistical machine translation models (Cho et al., 2014), they perform most accurately when given large amounts of text which makes them less useful for the translation of low-resource languages. Hupa (Pacific Athabaskan) and Croatian (Slavic) are both languages for which it is more difficult to collect training data. This project investigated the training of two separate neural models for Hupa-English and Croatian-English translation. Along with general translation and training accuracy, the models' performance was assessed based on how well they learned the morphology of the languages, especially noun declension in Croatian and verbal morphology in Hupa.
